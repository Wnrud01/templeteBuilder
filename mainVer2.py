import os
import json
import re
from typing import TypedDict, List, Dict, Optional
import uuid

# Pydantic ë° LangChain í˜¸í™˜ì„±ì„ ìœ„í•œ ì„í¬íŠ¸
from pydantic import PrivateAttr

# LangChain ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders.base import BaseLoader
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver
from dotenv import load_dotenv

# FlashRank ì„í¬íŠ¸
try:
    from flashrank import Ranker, RerankRequest
    from langchain.retrievers.document_compressors.base import BaseDocumentCompressor
    from langchain_core.callbacks.manager import Callbacks
except ImportError:
    print("FlashRank ë˜ëŠ” ê´€ë ¨ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'pip install flashrank'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    BaseDocumentCompressor = object
    Ranker = None

class FlashRankRerank(BaseDocumentCompressor):
    _ranker: Ranker = PrivateAttr()
    top_n: int = 3
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        if Ranker:
            self._ranker = Ranker()
    class Config:
        arbitrary_types_allowed = True
    def compress_documents(self, documents: List[Document], query: str, callbacks: Callbacks | None = None) -> List[Document]:
        if not documents or not Ranker: return documents[:self.top_n]
        passages = [{"id": i, "text": doc.page_content, "metadata": doc.metadata} for i, doc in enumerate(documents)]
        rerank_request = RerankRequest(query=query, passages=passages)
        reranked_results = self._ranker.rerank(rerank_request)
        final_docs = []
        for item in reranked_results[:self.top_n]:
            doc = documents[item['id']]
            doc.metadata["relevance_score"] = item['score']
            final_docs.append(doc)
        return final_docs

# --- 0. ì´ˆê¸° ì„¤ì • ---
load_dotenv()
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")

# --- 1. ë°ì´í„° ì¤€ë¹„ ---
retriever_compliance, retriever_generation, retriever_whitelist, retriever_rejected, retriever_guide = None, None, None, None, None

def load_jsonl_to_docs(file_path: str) -> List[Document]:
    docs = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data = json.loads(line)
                    content = data.get("content")
                    metadata = data.get("metadata", {})
                    doc = Document(page_content=content, metadata=metadata)
                    docs.append(doc)
        print(f"âœ… {len(docs)}ê°œì˜ ë¬¸ì„œë¥¼ '{file_path}'ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print(f"ğŸš¨ ê²½ê³ : '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except json.JSONDecodeError as e:
        print(f"ğŸš¨ ì˜¤ë¥˜: {file_path} íŒŒì¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}")
    return docs

def load_line_by_line(file_path: str) -> List[Document]:
    docs = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    docs.append(Document(page_content=line.strip()))
        print(f"âœ… {len(docs)}ê°œì˜ í…œí”Œë¦¿ì„ '{file_path}'ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print(f"ğŸš¨ ê²½ê³ : '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return docs

def load_by_separator(file_path: str, separator: str = '---') -> List[Document]:
    docs = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        items = [section.strip() for section in content.split(separator) if section.strip()]
        for item in items:
            docs.append(Document(page_content=item))
        print(f"âœ… {len(docs)}ê°œì˜ í•­ëª©ì„ '{file_path}'ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except FileNotFoundError:
        print(f"ğŸš¨ ê²½ê³ : '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return docs

def setup_retrievers():
    global retriever_compliance, retriever_generation, retriever_whitelist, retriever_rejected, retriever_guide
    if all([retriever_compliance, retriever_generation, retriever_whitelist, retriever_rejected, retriever_guide]):
        print("Retrieverê°€ ì´ë¯¸ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    print("Retriever ì„¤ì • ì‹œì‘...")

    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    docs_whitelist = load_line_by_line('./data/approved_templates.txt')
    docs_rejected = load_by_separator('./data/rejected_templates.txt')
    docs_compliance = load_jsonl_to_docs('./data/compliance_rules.jsonl')
    docs_guide = load_jsonl_to_docs('./data/alimtalk_guide.jsonl')

    try:
        docs_generation = TextLoader("./data/generation_rules.txt", encoding='utf-8').load()
        print(f"âœ… {len(docs_generation)}ê°œì˜ ë¬¸ì„œë¥¼ './data/generation_rules.txt'ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ ê²½ê³ : generation_rules.txt ë¡œë“œ ì‹¤íŒ¨ - {e}")
        docs_generation = []

    def create_hybrid_retriever(collection_name, docs, split_docs=False):
        if not docs:
            print(f"âš ï¸  '{collection_name}'ì— ëŒ€í•œ ë¬¸ì„œê°€ ì—†ì–´ ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None

        if split_docs:
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
            docs = text_splitter.split_documents(docs)

        vectorstore = Chroma.from_documents(docs, embeddings)
        vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 7})

        keyword_retriever = BM25Retriever.from_documents(docs)
        keyword_retriever.k = 7

        ensemble_retriever = EnsembleRetriever(retrievers=[vector_retriever, keyword_retriever], weights=[0.5, 0.5])

        if Ranker:
            compressor = FlashRankRerank(top_n=3)
            return ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)

        return ensemble_retriever

    retriever_whitelist = create_hybrid_retriever("whitelist_templates", docs_whitelist)
    retriever_rejected = create_hybrid_retriever("rejected_templates", docs_rejected)
    retriever_compliance = create_hybrid_retriever("compliance_rules", docs_compliance)
    retriever_guide = create_hybrid_retriever("alimtalk_guide", docs_guide)
    retriever_generation = create_hybrid_retriever("generation_rules", docs_generation, split_docs=True)

    print("âœ… ëª¨ë“  Retriever ì„¤ì • ì™„ë£Œ!")


# --- 2. LangGraph íŒŒì´í”„ë¼ì¸ ì •ì˜ ---
class GraphState(TypedDict):
    original_request: str
    request_category: Dict[str, str]
    recommendations: List[Dict]
    user_choice_1: str
    chosen_template: Optional[str]
    available_styles: List[Dict]
    user_choice_2: str
    final_request: str
    template_draft: str
    validation_result: Dict
    correction_attempts: int
    retrieved_guide: str
    retrieved_examples: str
    retrieved_rejected_examples: str

llm = ChatOpenAI(model="gpt-4o", temperature=0.2)

classification_prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬, ì•„ë˜ ì œê³µëœ 1ì°¨, 2ì°¨ ì¹´í…Œê³ ë¦¬ ì¤‘ì—ì„œ ê°€ì¥ ì í•©í•œ ê²ƒì„ í•˜ë‚˜ì”© ì„ íƒí•´ì£¼ì„¸ìš”.
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆ: {{"ë¶„ë¥˜ 1ì°¨": "êµ¬ë§¤", "ë¶„ë¥˜ 2ì°¨": "êµ¬ë§¤ì™„ë£Œ"}}

# 1ì°¨ ë¶„ë¥˜ ì˜µì…˜:
íšŒì›, êµ¬ë§¤, ì˜ˆì•½, ì„œë¹„ìŠ¤ì´ìš©, ë¦¬í¬íŒ…, ë°°ì†¡, ë²•ì ê³ ì§€, ì—…ë¬´ì•Œë¦¼, ì¿ í°/í¬ì¸íŠ¸, ê¸°íƒ€

# 2ì°¨ ë¶„ë¥˜ ì˜µì…˜:
íšŒì›ê°€ì…, ì¸ì¦/ë¹„ë°€ë²ˆí˜¸/ë¡œê·¸ì¸, íšŒì›ì •ë³´/íšŒì›í˜œíƒ, êµ¬ë§¤ì™„ë£Œ, ìƒí’ˆê°€ì…, ì§„í–‰ìƒíƒœ, êµ¬ë§¤ì·¨ì†Œ, êµ¬ë§¤ì˜ˆì•½/ì…ê³ ì•Œë¦¼, ì˜ˆì•½ì™„ë£Œ/ì˜ˆì•½ë‚´ì—­, ì˜ˆì•½ìƒíƒœ, ì˜ˆì•½ì·¨ì†Œ, ì˜ˆì•½ì•Œë¦¼/ë¦¬ë§ˆì¸ë“œ, ì´ìš©ì•ˆë‚´/ê³µì§€, ì‹ ì²­ì ‘ìˆ˜, ì²˜ë¦¬ì™„ë£Œ, ì´ìš©ë„êµ¬, ë°©ë¬¸ì„œë¹„ìŠ¤, í”¼ë“œë°± ìš”ì²­, êµ¬ë§¤ê°ì‚¬/ì´ìš©í™•ì¸, ë¦¬ë§ˆì¸ë“œ, í”¼ë“œë°±, ìš”ê¸ˆì²­êµ¬, ê³„ì•½/ê²¬ì , ì•ˆì „/í”¼í•´ì˜ˆë°©, ë‰´ìŠ¤ë˜í„°, ê±°ë˜ì•Œë¦¼, ë°°ì†¡ìƒíƒœ, ë°°ì†¡ì˜ˆì •, ë°°ì†¡ì™„ë£Œ, ë°°ì†¡ì‹¤íŒ¨, ìˆ˜ì‹ ë™ì˜, ê°œì¸ì •ë³´, ì•½ê´€ë³€ê²½, íœ´ë©´ ê´€ë ¨, ì£¼ë¬¸/ì˜ˆì•½, ë‚´ë¶€ ì—…ë¬´ ì•Œë¦¼, ì¿ í°ë°œê¸‰, ì¿ í°ì‚¬ìš©, í¬ì¸íŠ¸ì ë¦½, í¬ì¸íŠ¸ì‚¬ìš©, ì¿ í°/í¬ì¸íŠ¸ì•ˆë‚´, ê¸°íƒ€

# ì‚¬ìš©ì ìš”ì²­:
{original_request}
"""
)

generation_prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ êµ¬ì²´ì ì¸ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ì•Œë¦¼í†¡ í…œí”Œë¦¿ì„ ìƒì„±í•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

# ìµœì¢… ëª©í‘œ:
ì•„ë˜ 'ìµœì¢… ìš”ì²­'ì„ ë§Œì¡±í•˜ëŠ” í…œí”Œë¦¿ ì´ˆì•ˆì„ ìƒì„±í•˜ì„¸ìš”.

# ì°¸ê³  ìë£Œ:
- **ê´€ë ¨ ì œì‘ ê°€ì´ë“œ**: 
{guide}

- **ìœ ì‚¬ ì„±ê³µ ì‚¬ë¡€**: 
{examples}

- **ìœ ì‚¬ ì‹¤íŒ¨ ì‚¬ë¡€ (ì´ëŸ° ì‹¤ìˆ˜ë¥¼ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”)**: 
{rejected_examples}

# ìµœì¢… ìš”ì²­:
{final_request}

# í…œí”Œë¦¿ ì´ˆì•ˆ (ìœ„ ëª¨ë“  ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬ ìš”ì²­ì— ê°€ì¥ ë¶€í•©í•˜ëŠ” ì™„ë²½í•œ í…œí”Œë¦¿ í•˜ë‚˜ë§Œ ìƒì„±):
"""
)

validation_prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì •ë³´í†µì‹ ë§ë²• ë° ë‚´ë¶€ ê·œì •ì„ ê²€ìˆ˜í•˜ëŠ” ë§¤ìš° ê¼¼ê¼¼í•œ AI ì‹¬ì‚¬ê´€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ íŒë‹¨ì€ ëª…í™•í•œ ê·¼ê±°ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.
    ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

    # ê²€ìˆ˜ ëŒ€ìƒ í…œí”Œë¦¿:
    {draft}

    # ê´€ë ¨ ê·œì • (ë©”íƒ€ë°ì´í„° í¬í•¨):
    {rules}

    # ì§€ì‹œì‚¬í•­:
    1. 'ê²€ìˆ˜ ëŒ€ìƒ í…œí”Œë¦¿'ì´ ì •ë³´ì„±ì¸ì§€ ê´‘ê³ ì„±ì¸ì§€ ë¨¼ì € íŒë‹¨í•˜ì„¸ìš”.
    2. [ì •ë³´ì„±ì¼ ê²½ìš°]: 'ê´€ë ¨ ê·œì •'ì„ ìœ„ë°˜í•˜ëŠ”ì§€ ê²€í† í•˜ì„¸ìš”. ìœ„ë°˜ ì‚¬í•­ì´ ì—†ë‹¤ë©´ `{{"status": "accept"}}` ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”. ìœ„ë°˜ ì‚¬í•­ì´ ìˆë‹¤ë©´, ì–´ë–¤ ê·œì¹™(rule_id)ì„ ì–´ë–»ê²Œ ìœ„ë°˜í–ˆëŠ”ì§€ êµ¬ì²´ì ì¸ ì´ìœ ì™€ í•¨ê»˜ `{{"status": "reject", "reason": "ê·œì¹™ ìœ„ë°˜: [êµ¬ì²´ì  ì„¤ëª…]"}}` í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    3. [ê´‘ê³ ì„±ì¼ ê²½ìš°]: ì–´ë–¤ ë¬¸êµ¬ ë•Œë¬¸ì— ê´‘ê³ ì„±ì¸ì§€ ì„¤ëª…ê³¼ í•¨ê»˜ `{{"status": "reject", "reason": "ê´‘ê³ ì„± ë©”ì‹œì§€: [êµ¬ì²´ì  ì„¤ëª…]"}}` í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    """
)

correction_prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ê¹Œë‹¤ë¡œìš´ ì‹¬ì‚¬ê´€ì„ í†µê³¼ì‹œí‚¤ê¸° ìœ„í•´ í…œí”Œë¦¿ì„ ìˆ˜ì •í•˜ëŠ” ì°½ì˜ì ì¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.

    # ìˆ˜ì • ëª©í‘œ:
    ì•„ë˜ 'ë°˜ë ¤ ì‚¬ìœ 'ë¥¼ ì°¸ê³ í•˜ì—¬ 'ê¸°ì¡´ ì´ˆì•ˆ'ì„ ìˆ˜ì •í•˜ì„¸ìš”. ìˆ˜ì •ëœ í…œí”Œë¦¿ì€ ë°˜ë“œì‹œ ì •ë³´ì„± ë©”ì‹œì§€ë¡œ ë¶„ë¥˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

    # ìˆ˜ì • ì „ëµ (í˜„ì¬ {attempts}ì°¨ ì‹œë„):
    {strategy}

    # ê¸°ì¡´ ì´ˆì•ˆ:
    {draft}

    # ë°˜ë ¤ ì‚¬ìœ :
    {reason}
    
    # ì°¸ê³ : ê³ ê°ê³¼ì˜ ì—°ê²°ê³ ë¦¬ (ì´ ì¤‘ í•˜ë‚˜ë¥¼ í™œìš©í•˜ì—¬ ì •ë³´ì„±ìœ¼ë¡œ ì „í™˜)
    - ê°€ì • 1: ê³ ê°ì€ "ë¸Œëœë“œ í–‰ì‚¬ ì•Œë¦¼ ìˆ˜ì‹ "ì— ëª…ì‹œì ìœ¼ë¡œ ë™ì˜í–ˆìŠµë‹ˆë‹¤.
    - ê°€ì • 2: ê³ ê°ì€ VIPì´ë©°, "ì…ì  ë¸Œëœë“œ í–‰ì‚¬ ìš°ì„  ì•Œë¦¼" í˜œíƒì´ ìˆìŠµë‹ˆë‹¤.
    - ê°€ì • 3: ê³ ê°ì€ ê³¼ê±° ì œí’ˆ êµ¬ë§¤ ì‹œ "ê´€ë ¨ í˜œíƒ ì •ë³´ ìˆ˜ì‹ "ì— ë™ì˜í–ˆìŠµë‹ˆë‹¤.

    # ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ (ë°˜ë“œì‹œ í…œí”Œë¦¿ ë‚´ìš©ë§Œ ê°„ê²°í•˜ê²Œ ì¶œë ¥):
    """
)

# --- ì¸í„°ë™í‹°ë¸Œ ì›Œí¬í”Œë¡œìš° ë…¸ë“œë“¤ ---
def classify_request(state: GraphState):
    print("\n--- 1. ì‚¬ìš©ì ìš”ì²­ ë¶„ë¥˜ ì‹œì‘ ---")
    original_request = state['original_request']
    chain = classification_prompt | llm | JsonOutputParser()
    try:
        category = chain.invoke({"original_request": original_request})
        state['request_category'] = category
        print(f"âœ… ìš”ì²­ ë¶„ë¥˜ ì™„ë£Œ: {category}")
    except Exception as e:
        print(f"ğŸš¨ ìš”ì²­ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
        state['request_category'] = {}
    return state

def recommend_templates(state: GraphState):
    print("\n--- 2. ìœ ì‚¬ í…œí”Œë¦¿ ì¶”ì²œ ì‹œì‘ ---")
    original_request = state['original_request']

    if retriever_whitelist:
        recommended_docs = retriever_whitelist.invoke(original_request)
        recommendations = [{"id": i+1, "content": doc.page_content} for i, doc in enumerate(recommended_docs)]
        state['recommendations'] = recommendations
        print(f"âœ… ì‚¬ìš©ìì˜ ìš”ì²­ê³¼ ìœ ì‚¬í•œ ê¸°ì¡´ í…œí”Œë¦¿ì„ {len(recommendations)}ê°œ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    else:
        state['recommendations'] = []
        print("âš ï¸ ìœ ì‚¬ í…œí”Œë¦¿ ë¦¬íŠ¸ë¦¬ë²„ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì¶”ì²œì„ ê±´ë„ˆëœë‹ˆë‹¤.")

    return state

def present_styles(state: GraphState):
    print("\n--- 3. í…œí”Œë¦¿ ìŠ¤íƒ€ì¼ ì„ íƒ ì œì‹œ ---")

    if retriever_guide:
        try:
            base_retriever = retriever_guide.base_retriever
            if hasattr(base_retriever, 'base_retriever'):
                vectorstore = base_retriever.base_retriever.vectorstore
            elif hasattr(base_retriever, 'retrievers'):
                vectorstore = base_retriever.retrievers[0].vectorstore
            else:
                vectorstore = base_retriever.vectorstore

            style_docs = vectorstore.similarity_search(
                "ê°•ì¡° ìœ í˜•",
                filter={"part_title": "ê°•ì¡° ìœ í˜•"}
            )
        except Exception as e:
            print(f"ğŸš¨ ìŠ¤íƒ€ì¼ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
            style_docs = retriever_guide.invoke("í…œí”Œë¦¿ ê°•ì¡° ìœ í˜•")

        available_styles = []
        seen_titles = set()
        for doc in style_docs:
            title = doc.metadata.get('section_title')
            if title and title not in seen_titles:
                summary = doc.page_content.split('\n')[0]
                available_styles.append({"title": title, "summary": summary})
                seen_titles.add(title)
        state['available_styles'] = available_styles
    else:
        state['available_styles'] = []
        print("âš ï¸ ê°€ì´ë“œ ë¦¬íŠ¸ë¦¬ë²„ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìŠ¤íƒ€ì¼ ì œì‹œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    return state

def prepare_final_request(state: GraphState):
    print("\n--- 4. ìµœì¢… ìƒì„± ìš”ì²­ ì¤€ë¹„ ---")
    original_request = state['original_request']

    if state.get('user_choice_1') == 'recommend':
        chosen_template_content = state['chosen_template']
        final_request = f"'{original_request}' ìš”ì²­ì„ ë°˜ì˜í•˜ì—¬, ì•„ë˜ í…œí”Œë¦¿ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì • ë° í™•ì¥í•´ì£¼ì„¸ìš”.\n\n[ê¸°ë°˜ í…œí”Œë¦¿]:\n{chosen_template_content}"
    else:
        chosen_style_title = state['user_choice_2']
        final_request = f"'{original_request}' ìš”ì²­ì— ë§ì¶°, '{chosen_style_title}' ìŠ¤íƒ€ì¼ì˜ ìƒˆë¡œìš´ í…œí”Œë¦¿ì„ ìƒì„±í•´ì£¼ì„¸ìš”."

    state['final_request'] = final_request
    print(f"âœ… ìµœì¢… ìƒì„± ìš”ì²­ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return state

def generate_draft(state: GraphState):
    print("\n--- 5. ê°€ì´ë“œ ê¸°ë°˜ ì´ˆì•ˆ ìƒì„± ì‹œì‘ ---")
    final_request = state['final_request']

    guide_docs = retriever_guide.invoke(final_request) if retriever_guide else []
    example_docs = retriever_whitelist.invoke(final_request) if retriever_whitelist else []
    rejected_docs = retriever_rejected.invoke(final_request) if retriever_rejected else []
    generation_docs = retriever_generation.invoke(final_request) if retriever_generation else []

    guide = "\n\n".join([f"ê°€ì´ë“œ ì„¹ì…˜: {doc.metadata.get('section_title', '')}\n{doc.page_content}" for doc in guide_docs])
    guide += "\n\n" + "\n\n".join([doc.page_content for doc in generation_docs])
    examples = "\n\n".join([doc.page_content for doc in example_docs])
    rejected_examples = "\n\n".join([doc.page_content for doc in rejected_docs])

    state.update({ "retrieved_guide": guide, "retrieved_examples": examples, "retrieved_rejected_examples": rejected_examples })

    chain = generation_prompt | llm | StrOutputParser()
    draft = chain.invoke({ "guide": guide, "examples": examples, "rejected_examples": rejected_examples, "final_request": final_request })

    state['template_draft'] = draft
    state['correction_attempts'] = 0
    print("âœ… ì´ˆì•ˆ ìƒì„± ì™„ë£Œ.")
    print(f"ìƒì„±ëœ ì´ˆì•ˆ:\n---\n{draft}\n---")
    return state

def validate_draft(state: GraphState):
    print(f"\n--- 6. ê·œì • ì¤€ìˆ˜ ê²€ì¦ (ì‹œë„: {state['correction_attempts'] + 1}) ---")
    draft = state['template_draft']

    rules_docs = retriever_compliance.invoke(draft) if retriever_compliance else []
    rules = "\n\n".join([f"Rule ID: {doc.metadata.get('rule_id', 'N/A')}\n{doc.page_content}" for doc in rules_docs])

    validation_chain = validation_prompt | llm | JsonOutputParser()
    try:
        validation_result = validation_chain.invoke({"draft": draft, "rules": rules})
    except Exception as e:
        print(f"ğŸš¨ ê²€ì¦ ì¤‘ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}. ë°˜ë ¤ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        validation_result = {"status": "reject", "reason": "ê²€ì¦ ì‹œìŠ¤í…œ ì˜¤ë¥˜"}

    state['validation_result'] = validation_result

    if validation_result.get("status") == "accept":
        print("âœ… ê²€ì¦ í†µê³¼!")
    else:
        print(f"ğŸš¨ ê²€ì¦ ë°˜ë ¤. ì´ìœ : {validation_result.get('reason')}")

    return state

def correct_draft(state: GraphState):
    print("\n--- 7. AI ìë™ ìˆ˜ì • ì‹œì‘ ---")

    attempts = state['correction_attempts']
    draft = state['template_draft']
    reason = state['validation_result'].get('reason', 'ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ ')

    if attempts == 0:
        strategy = "1ì°¨ ìˆ˜ì •: ë°˜ë ¤ ì‚¬ìœ ì— ì–¸ê¸‰ëœ ê´‘ê³ ì„± í‘œí˜„ì´ë‚˜ ë¬¸êµ¬ë¥¼ ìµœì†Œí•œìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì •ë³´ì„±ìœ¼ë¡œ ë§Œë“œì„¸ìš”. (ì˜ˆ: 'ë‹¨ë… íŠ¹ê°€!' -> 'íšŒì›ë‹˜ê»˜ ì ìš©ë˜ëŠ” í˜œíƒ ì•ˆë‚´')"
    elif attempts == 1:
        strategy = "2ì°¨ ìˆ˜ì •: ì¢€ ë” ì ê·¹ì ìœ¼ë¡œ ê´‘ê³ ì„± ë‹¨ì–´ë¥¼ ì •ë³´ì„± ë‹¨ì–´ë¡œ ìˆœí™”í•˜ì„¸ìš”. ê³ ê°ì´ ìš”ì²­í•œ ì •ë³´(ì˜ˆ: ì£¼ë¬¸, ì˜ˆì•½, í¬ì¸íŠ¸)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ì¬êµ¬ì„±í•˜ì„¸ìš”."
    else:
        strategy = "3ì°¨(ìµœì¢…) ìˆ˜ì •: ê´€ì ì„ ì™„ì „íˆ ë°”ê¾¸ì„¸ìš”. 'ê³ ê°ê³¼ì˜ ì—°ê²°ê³ ë¦¬' ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬, ì´ ë©”ì‹œì§€ê°€ ê³ ê°ì˜ ì‚¬ì „ ë™ì˜ë‚˜ ìê²©ì— ë”°ë¥¸ 'ì •ë³´ ì•ˆë‚´'ì„ì„ ëª…í™•íˆ í•˜ëŠ” ë¬¸ì¥ì„ ì„œë‘ì— ì¶”ê°€í•˜ì—¬ ë©”ì‹œì§€ ì „ì²´ì˜ ì„±ê²©ì„ ë°”ê¾¸ì„¸ìš”."

    print(f"ìˆ˜ì • ì „ëµ: {strategy}")

    correction_chain = correction_prompt | llm | StrOutputParser()
    corrected_draft = correction_chain.invoke({
        "attempts": attempts + 1,
        "strategy": strategy,
        "draft": draft,
        "reason": reason
    })

    state['template_draft'] = corrected_draft
    state['correction_attempts'] = attempts + 1

    print("âœ… AI ìˆ˜ì • ì™„ë£Œ. ìƒˆë¡œìš´ ì´ˆì•ˆ:")
    print(f"---\n{corrected_draft}\n---")

    return state

def get_user_correction(state: GraphState):
    print("\n--- 8. ì‚¬ìš©ì ì§ì ‘ ìˆ˜ì • ---")
    final_draft = state['template_draft']
    reason = state['validation_result'].get('reason', 'ì•Œ ìˆ˜ ì—†ìŒ')

    print("AIì˜ ìë™ ìˆ˜ì •ìœ¼ë¡œ ê²€ì¦ì„ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    print("ë§ˆì§€ë§‰ìœ¼ë¡œ ì§ì ‘ ìˆ˜ì •í•  ê¸°íšŒë¥¼ ë“œë¦½ë‹ˆë‹¤.")
    print("\nğŸ”¥ í˜„ì¬ í…œí”Œë¦¿ (ë°˜ë ¤) ğŸ”¥")
    print(final_draft)
    print(f"\nìµœì¢… ë°˜ë ¤ ì‚¬ìœ : {reason}")
    print("-" * 50)

    print("ìœ„ í…œí”Œë¦¿ì„ ì§ì ‘ ìˆ˜ì •í•´ì£¼ì„¸ìš”. ìˆ˜ì •ì„ ë§ˆì¹œ í›„ Enterë¥¼ ë‘ ë²ˆ ëˆŒëŸ¬ ì…ë ¥ì„ ì™„ë£Œí•˜ì„¸ìš”.")
    user_input_lines = []
    while True:
        try:
            line = input()
            if not line:
                break
            user_input_lines.append(line)
        except EOFError:
            break

    user_corrected_draft = "\n".join(user_input_lines)

    if not user_corrected_draft.strip():
        print("ì…ë ¥ì´ ì—†ì–´ ìˆ˜ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        state['correction_attempts'] += 1
        return state

    state['template_draft'] = user_corrected_draft
    state['correction_attempts'] += 1

    print("\nâœ… ì‚¬ìš©ì ìˆ˜ì •ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì¢… ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print(f"---\n{user_corrected_draft}\n---")

    return state

def decide_recommendation_branch(state: GraphState):
    if state.get('user_choice_1') == 'recommend':
        return "prepare_request"
    else:
        return "present_styles"

def decide_correction_or_end(state: GraphState):
    if state['validation_result'].get("status") == "accept":
        return "end"

    if state['correction_attempts'] < 3:
        return "correct_ai"

    if state['correction_attempts'] == 3:
        return "correct_user"

    return "end"

def build_graph():
    workflow = StateGraph(GraphState)

    workflow.add_node("classify_request", classify_request)
    workflow.add_node("recommend_templates", recommend_templates)
    workflow.add_node("present_styles", present_styles)
    workflow.add_node("prepare_final_request", prepare_final_request)
    workflow.add_node("generate_draft", generate_draft)
    workflow.add_node("validate_draft", validate_draft)
    workflow.add_node("correct_draft", correct_draft)
    workflow.add_node("get_user_correction", get_user_correction)

    workflow.set_entry_point("classify_request")

    workflow.add_edge("classify_request", "recommend_templates")
    workflow.add_conditional_edges(
        "recommend_templates",
        decide_recommendation_branch,
        {"prepare_request": "prepare_final_request", "present_styles": "present_styles"}
    )
    workflow.add_edge("present_styles", "prepare_final_request")
    workflow.add_edge("prepare_final_request", "generate_draft")
    workflow.add_edge("generate_draft", "validate_draft")

    workflow.add_conditional_edges(
        "validate_draft",
        decide_correction_or_end,
        {
            "correct_ai": "correct_draft",
            "correct_user": "get_user_correction",
            "end": END
        }
    )

    workflow.add_edge("correct_draft", "validate_draft")
    workflow.add_edge("get_user_correction", "validate_draft")

    return workflow.compile(
        checkpointer=MemorySaver(),
        interrupt_after=["recommend_templates", "present_styles"]
    )

# --- 3. ë©”ì¸ ì‹¤í–‰ ë¡œì§ (ì¸í„°ë™í‹°ë¸Œ) ---
if __name__ == "__main__":
    setup_retrievers()
    app = build_graph()

    print("\n==================================================")
    print("í…œí”Œë¦¿ ìƒì„± ì–´ì‹œìŠ¤í„´íŠ¸ V7.4 (ì…ë ¥ ëŒ€ê¸° ìˆ˜ì •)")
    print("==================================================")
    original_request = input("ì–´ë–¤ í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ ë“œë¦´ê¹Œìš”? >> ")

    thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}

    inputs = {"original_request": original_request}

    # 1ë‹¨ê³„: ì²« ë²ˆì§¸ ì¤‘ë‹¨ì ê¹Œì§€ ì‹¤í–‰
    current_state = None
    for event in app.stream(inputs, config=config):
        (node, state) = next(iter(event.items()))
        current_state = state
        if node == "recommend_templates":
            break

    # 2ë‹¨ê³„: ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    recommendations = current_state.get("recommendations", [])
    print("\n--------------------------------------------------")
    print("ğŸ§ ì´ëŸ° í…œí”Œë¦¿ì€ ì–´ë– ì„¸ìš”? (ìœ ì‚¬ í…œí”Œë¦¿ ì¶”ì²œ)")
    if recommendations:
        for r in recommendations:
            if r and r.get('content'):
                print(f"\n[{r['id']}] {r['content']}")
    else:
        print("ì¶”ì²œí•  ë§Œí•œ ìœ ì‚¬ í…œí”Œë¦¿ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    print("\n--------------------------------------------------")

    choice = input("ì‚¬ìš©í•  í…œí”Œë¦¿ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜, ìƒˆë¡œ ë§Œë“¤ë ¤ë©´ '0'ì„ ì…ë ¥í•˜ì„¸ìš” >> ")

    # 3ë‹¨ê³„: ì‚¬ìš©ì ì…ë ¥ì— ë”°ë¼ ìƒíƒœ ì—…ë°ì´íŠ¸ í›„ ë‚˜ë¨¸ì§€ ê·¸ë˜í”„ ì‹¤í–‰
    final_events = []
    if choice != '0' and choice.isdigit() and recommendations and 1 <= int(choice) <= len(recommendations):
        # ì¶”ì²œ í…œí”Œë¦¿ ì„ íƒ
        user_choice_data = {
            "user_choice_1": "recommend",
            "chosen_template": recommendations[int(choice)-1]['content']
        }
        app.update_state(config, user_choice_data)
        # ë‚˜ë¨¸ì§€ ê·¸ë˜í”„ ì‹¤í–‰
        final_events = list(app.stream(None, config=config))
    else:
        # ìƒˆë¡œ ë§Œë“¤ê¸° ì„ íƒ
        app.update_state(config, {"user_choice_1": "new"})
        # ë‹¤ìŒ ì¤‘ë‹¨ì (ìŠ¤íƒ€ì¼ ì œì‹œ)ê¹Œì§€ ì‹¤í–‰
        for event in app.stream(None, config=config):
            (node, state) = next(iter(event.items()))
            current_state = state
            if node == "present_styles":
                break

        # ìŠ¤íƒ€ì¼ ì„ íƒ ì…ë ¥ ë°›ê¸°
        available_styles = current_state.get("available_styles", [])
        print("\n--------------------------------------------------")
        print("ğŸ¨ ìƒˆë¡œ ë§Œë“¤ í…œí”Œë¦¿ì˜ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        if available_styles:
            for i, s in enumerate(available_styles):
                if s and s.get('title'):
                    print(f"[{i+1}] {s['title']}: {s.get('summary', '')}")
        else:
            print("ì„ íƒ ê°€ëŠ¥í•œ ìŠ¤íƒ€ì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸í˜•ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.")
        print("\n--------------------------------------------------")

        style_choice_num = input(f"ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1-{len(available_styles) if available_styles else 1}) >> ")

        chosen_style = ""
        if available_styles and style_choice_num.isdigit() and 1 <= int(style_choice_num) <= len(available_styles):
            chosen_style = available_styles[int(style_choice_num)-1]['title']
        else:
            print("ì˜ëª»ëœ ì…ë ¥ì´ê±°ë‚˜ ì„ íƒ ê°€ëŠ¥í•œ ìŠ¤íƒ€ì¼ì´ ì—†ìŠµë‹ˆë‹¤. 'ê¸°ë³¸í˜•'ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            chosen_style = "ê¸°ë³¸í˜•"

        # ìŠ¤íƒ€ì¼ ì„ íƒ ìƒíƒœ ì—…ë°ì´íŠ¸ í›„ ë‚˜ë¨¸ì§€ ê·¸ë˜í”„ ì‹¤í–‰
        app.update_state(config, {"user_choice_2": chosen_style})
        final_events = list(app.stream(None, config=config))

    # 4ë‹¨ê³„: ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n================ ìµœì¢… ê²°ê³¼ ================")
    if final_events:
        last_node, final_state = next(iter(final_events[-1].items()))

        if final_state:
            final_draft = final_state.get('template_draft', 'ì˜¤ë¥˜: ìµœì¢… í…œí”Œë¦¿ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
            validation_result = final_state.get('validation_result', {})

            if validation_result.get('status') == 'accept':
                print("ğŸ‰ ìµœì¢… í…œí”Œë¦¿ (ìŠ¹ì¸) ğŸ‰")
                print(final_draft)
            else:
                print("ğŸ”¥ ìµœì¢… í…œí”Œë¦¿ (ë°˜ë ¤) ğŸ”¥")
                print(final_draft)
                print(f"\nìµœì¢… ë°˜ë ¤ ì‚¬ìœ : {validation_result.get('reason', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
        else:
            print("ì˜¤ë¥˜: ê·¸ë˜í”„ì˜ ìµœì¢… ìƒíƒœë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("í…œí”Œë¦¿ ìƒì„± ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆê±°ë‚˜ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("============================================")
