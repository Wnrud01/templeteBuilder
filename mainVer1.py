import os
import json
import re
from typing import TypedDict, List, Optional

# Pydantic ë° LangChain í˜¸í™˜ì„±ì„ ìœ„í•œ ì„í¬íŠ¸
from pydantic import BaseModel, Field, PrivateAttr

# LangChain ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders.base import BaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langgraph.graph import StateGraph, END
from dotenv import load_dotenv

# FlashRank ì„í¬íŠ¸
try:
    from flashrank import Ranker, RerankRequest
    from langchain.retrievers.document_compressors.base import BaseDocumentCompressor
    from langchain_core.callbacks.manager import Callbacks
except ImportError:
    print("FlashRank ë˜ëŠ” ê´€ë ¨ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'pip install flashrank'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    BaseDocumentCompressor = object
    Ranker = None

# --- ìƒìˆ˜ ì •ì˜ ---
MAX_CORRECTION_ATTEMPTS = 3 # AI ìê°€ ìˆ˜ì • ìµœëŒ€ ì‹œë„ íšŸìˆ˜

class CustomRuleLoader(BaseLoader):
    def __init__(self, file_path: str, encoding: str = 'utf-8'):
        self.file_path = file_path
        self.encoding = encoding
    def load(self) -> List[Document]:
        docs = []
        try:
            with open(self.file_path, 'r', encoding=self.encoding) as f: content = f.read()
        except FileNotFoundError:
            print(f"ğŸš¨ ê²½ê³ : '{self.file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
            return []
        rule_blocks = re.findall(r'\[ê·œì¹™ ì‹œì‘\](.*?)\[ê·œì¹™ ë\]', content, re.DOTALL)
        for block in rule_blocks:
            lines, metadata, page_content, is_content_section = block.strip().split('\n'), {}, "", False
            for line in lines:
                if line.lower().startswith('content:'):
                    is_content_section = True
                    page_content += line[len('content:'):].strip() + "\n"
                    continue
                if is_content_section: page_content += line.strip() + "\n"
                else:
                    if ':' in line:
                        key, value = line.split(':', 1)
                        metadata[key.strip()] = value.strip()
            if page_content: docs.append(Document(page_content=page_content.strip(), metadata=metadata))
        print(f"âœ… {len(docs)}ê°œì˜ ê·œì¹™ì„ '{self.file_path}'ì—ì„œ êµ¬ì¡°í™”í•˜ì—¬ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return docs

class TemplateAnalysisResult(BaseModel):
    status: str = Field(description="í…œí”Œë¦¿ì˜ ìµœì¢… ìƒíƒœ (ì˜ˆ: 'accepted', 'rejected')")
    reason: str = Field(description="ë‹¤ë‹¨ê³„ ì¶”ë¡  ê³¼ì •ì„ í¬í•¨í•œ ìƒì„¸í•œ íŒë‹¨ ì´ìœ .")
    evidence: Optional[str] = Field(None, description="íŒë‹¨ì˜ ê·¼ê±°ê°€ ëœ ê·œì¹™ë“¤ì˜ rule_id ëª©ë¡ (ì‰¼í‘œë¡œ êµ¬ë¶„).")
    suggestion: Optional[str] = Field(None, description="ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì œì•ˆ.")
    revised_template: Optional[str] = Field(None, description="ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ë˜ê±°ë‚˜ ìˆ˜ì •ëœ í…œí”Œë¦¿ í…ìŠ¤íŠ¸. 'rejected' ìƒíƒœì¼ ê²½ìš° nullì´ì–´ì•¼ í•¨.")

class FlashRankRerank(BaseDocumentCompressor):
    _ranker: Ranker = PrivateAttr()
    top_n: int = 3
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._ranker = Ranker()
    class Config: arbitrary_types_allowed = True
    def compress_documents(self, documents: List[Document], query: str, callbacks: Callbacks | None = None) -> List[Document]:
        if not documents: return []
        rerank_request = RerankRequest(query=query, passages=[{"id": i, "text": doc.page_content, "metadata": doc.metadata} for i, doc in enumerate(documents)])
        reranked_results = self._ranker.rerank(rerank_request)
        final_docs = []
        for item in reranked_results[:self.top_n]:
            doc = documents[item['id']]
            doc.metadata["relevance_score"] = item['score']
            final_docs.append(doc)
        return final_docs

load_dotenv()
if not os.getenv("OPENAI_API_KEY"): raise ValueError("OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")

def load_line_by_line(file_path: str) -> List[str]:
    try:
        with open(file_path, 'r', encoding='utf-8') as f: items = [line.strip() for line in f if line.strip()]
        print(f"âœ… {len(items)}ê°œì˜ í•­ëª©ì„ '{file_path}'ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return items
    except FileNotFoundError:
        print(f"ğŸš¨ ê²½ê³ : '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return []

def load_by_separator(file_path: str, separator: str = '---') -> List[str]:
    try:
        with open(file_path, 'r', encoding='utf-8') as f: content = f.read()
        items = [section.strip() for section in content.split(separator) if section.strip()]
        print(f"âœ… {len(items)}ê°œì˜ í•­ëª©ì„ '{file_path}'ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return items
    except FileNotFoundError:
        print(f"ğŸš¨ ê²½ê³ : '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
        return []

APPROVED_TEMPLATES = load_line_by_line("./data/approved_templates.txt")
REJECTED_TEMPLATES_TEXT = load_by_separator("./data/rejected_templates.txt")

retriever_compliance, retriever_generation, retriever_whitelist, retriever_rejected = None, None, None, None

def setup_retrievers():
    global retriever_compliance, retriever_generation, retriever_whitelist, retriever_rejected
    if all([retriever_compliance, retriever_generation, retriever_whitelist, retriever_rejected]): return
    print("Retriever ì„¤ì • ì‹œì‘...")
    from chromadb.config import Settings
    docs_compliance = CustomRuleLoader("./data/compliance_rules.txt").load()
    docs_generation = CustomRuleLoader("./data/generation_rules.txt").load()
    docs_whitelist = [Document(page_content=t) for t in APPROVED_TEMPLATES]
    docs_rejected = [Document(page_content=t) for t in REJECTED_TEMPLATES_TEXT]
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vector_db_path = "./vector_db"
    client_settings = Settings(anonymized_telemetry=False)
    
    def create_db(name, docs):
        if docs: return Chroma.from_documents(docs, embeddings, collection_name=name, persist_directory=vector_db_path, client_settings=client_settings)
        return Chroma(collection_name=name, embedding_function=embeddings, persist_directory=vector_db_path, client_settings=client_settings)

    db_compliance, db_generation, db_whitelist, db_rejected = create_db("compliance_rules", docs_compliance), create_db("generation_rules", docs_generation), create_db("whitelist_templates", docs_whitelist), create_db("rejected_templates", docs_rejected)
    
    def create_hybrid_retriever(vectorstore, docs):
        if not docs: return vectorstore.as_retriever(search_kwargs={"k": 5})
        vector_retriever, keyword_retriever = vectorstore.as_retriever(search_kwargs={"k": 5}), BM25Retriever.from_documents(docs)
        keyword_retriever.k = 5
        ensemble_retriever = EnsembleRetriever(retrievers=[vector_retriever, keyword_retriever], weights=[0.5, 0.5])
        if Ranker:
            compressor = FlashRankRerank(top_n=3)
            return ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)
        return ensemble_retriever
        
    retriever_compliance, retriever_generation, retriever_whitelist, retriever_rejected = create_hybrid_retriever(db_compliance, docs_compliance), create_hybrid_retriever(db_generation, docs_generation), create_hybrid_retriever(db_whitelist, docs_whitelist), create_hybrid_retriever(db_rejected, docs_rejected)
    print("âœ… Retriever ì„¤ì • ì™„ë£Œ!")

class GraphState(TypedDict):
    original_request: str
    user_choice: str
    selected_style: str
    template_draft: str
    validation_result: Optional[TemplateAnalysisResult]
    correction_attempts: int

llm = ChatOpenAI(model="gpt-4o", temperature=0.2)

expansion_prompt = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í•µì‹¬ ì˜ë„ì™€ 'ì„ íƒëœ ìŠ¤íƒ€ì¼'ì„ ë°”íƒ•ìœ¼ë¡œ, ì •ë³´ê°€ í’ë¶€í•œ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ì´ˆì•ˆì„ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ **ì •ë³´ê°€ í™•ì¥ëœ í…œí”Œë¦¿ ì´ˆì•ˆ í•˜ë‚˜ë§Œ**ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ˆì•ˆ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ë¡œ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.
    # ì§€ì‹œì‚¬í•­
    1. 'ì‚¬ìš©ì í•µì‹¬ ì˜ë„'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, 'ì„ íƒëœ ìŠ¤íƒ€ì¼'ì— ë§ëŠ” ì™„ì „í•œ í…œí”Œë¦¿ ì´ˆì•ˆì„ ë§Œë“œì„¸ìš”.
    2. 'ìœ ì‚¬í•œ ì„±ê³µ ì‚¬ë¡€'ë¥¼ ì°¸ê³ í•˜ì—¬, ì–´ë–¤ ì •ë³´(ì˜ˆ: ì§€ì› ëŒ€ìƒ, ì‹ ì²­ ê¸°ê°„ ë“±)ë¥¼ ì¶”ê°€í•´ì•¼ í• ì§€ **ì¶”ë¡ **í•˜ê³ , ì ì ˆí•œ #{{ë³€ìˆ˜}}ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    # ì‚¬ìš©ì í•µì‹¬ ì˜ë„: {original_request}
    # ì„ íƒëœ ìŠ¤íƒ€ì¼: {style}
    # ìœ ì‚¬í•œ ì„±ê³µ ì‚¬ë¡€ (ì°¸ê³ ìš©): {examples}
    # í™•ì¥ëœ í…œí”Œë¦¿ ì´ˆì•ˆ (ì˜¤ì§ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥):"""
)

validation_prompt_structured = ChatPromptTemplate.from_template(
    """ë‹¹ì‹ ì€ ê³¼ê±° íŒë¡€ì™€ ë²•ê·œë¥¼ ê·¼ê±°ë¡œ íŒë‹¨í•˜ëŠ” ë§¤ìš° ê¼¼ê¼¼í•œ ìµœì¢… ì‹¬ì‚¬ê´€ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ JSON í˜•ì‹ì— ë§ì¶°ì„œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

    # ê²€ìˆ˜ ëŒ€ìƒ í…œí”Œë¦¿: {draft}
    # ê´€ë ¨ ê·œì • (ë©”íƒ€ë°ì´í„° í¬í•¨): {rules}
    # ìœ ì‚¬í•œ ê³¼ê±° ë°˜ë ¤ ì‚¬ë¡€ (íŒë¡€): {rejections}

    # ì§€ì‹œì‚¬í•­
    1. **(ë§¤ìš° ì¤‘ìš”) 'reason' í•„ë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ë‹¨ê³„ ì¶”ë¡  ê³¼ì •ì— ë”°ë¼ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”:**
        a. **ì‚¬ì‹¤ í™•ì¸:** ë¨¼ì €, 'ê²€ìˆ˜ ëŒ€ìƒ í…œí”Œë¦¿'ì— ì–´ë–¤ ë‚´ìš©(ì˜ˆ: ì¿ í°, í• ì¸ìœ¨, ì‚¬ìš©ì²˜ ë“±)ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
        b. **ê·œì • ì—°ê²°:** ë‹¤ìŒìœ¼ë¡œ, í™•ì¸ëœ ì‚¬ì‹¤ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ 'ê´€ë ¨ ê·œì •' ë˜ëŠ” 'ìœ ì‚¬í•œ ê³¼ê±° ë°˜ë ¤ ì‚¬ë¡€'ë¥¼ 1~3ê°œ ì°¾ì•„ ì—°ê²°í•˜ì„¸ìš”. ì´ë•Œ, ê° ê·¼ê±°ì˜ `rule_id`ì™€ ë‚´ìš©ì„ ë°˜ë“œì‹œ ì¸ìš©í•˜ì„¸ìš”.
        c. **ìµœì¢… ê²°ë¡ :** ë§ˆì§€ë§‰ìœ¼ë¡œ, ìœ„ ì‚¬ì‹¤ê³¼ ê·œì •ì„ ì¢…í•©í•˜ì—¬ ì™œ ì´ í…œí”Œë¦¿ì´ 'accepted' ë˜ëŠ” 'rejected'ì¸ì§€ ëª…í™•í•œ ê²°ë¡ ì„ ë‚´ë¦¬ì„¸ìš”.
    2. **'evidence' í•„ë“œì—ëŠ” ë‹¹ì‹ ì´ ì¸ìš©í•œ ê·œì¹™ë“¤ì˜ `rule_id`ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì„¸ìš”.** (ì˜ˆ: "COMP-DEF-002, COMP-CASE-003")
    3. ìœ„ë°˜ ì‚¬í•­ì´ ì—†ë‹¤ë©´ 'status'ë¥¼ 'accepted'ë¡œ ì„¤ì •í•˜ê³ , 'revised_template'ì— ì›ë³¸ ì´ˆì•ˆì„ ê·¸ëŒ€ë¡œ ë„£ìœ¼ì„¸ìš”.
    4. ìœ„ë°˜ ì‚¬í•­ì´ ìˆë‹¤ë©´ 'status'ë¥¼ 'rejected'ë¡œ ì„¤ì •í•˜ê³ , 'suggestion'ì— êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.
    5. ë§Œì•½ ê´‘ê³ ì„± ë‚´ìš©(í• ì¸, ì¿ í°, ì´ë²¤íŠ¸ ë“±)ì´ ë¬¸ì œë¼ë©´, 'suggestion'ì— 'ì¹œêµ¬í†¡' ì‚¬ìš©ì„ ê¶Œì¥í•˜ëŠ” ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.

    # ì¶œë ¥ í˜•ì‹ (JSON):
    {format_instructions}
    """
)

correction_prompt_template = """ë‹¹ì‹ ì€ ì§€ì ëœ ë¬¸ì œì ì„ í•´ê²°í•˜ì—¬ ë” ë‚˜ì€ ëŒ€ì•ˆì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ **ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ í•˜ë‚˜ë§Œ**ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ˆì•ˆ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ë¡œ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.

# ì›ë˜ ì‚¬ìš©ì ìš”ì²­: {original_request}
# ì´ì „ì— ì œì•ˆí–ˆë˜ í…œí”Œë¦¿ (ë°˜ë ¤ë¨): {rejected_draft}
# ë°˜ë ¤ ì‚¬ìœ  ë° ê°œì„  ì œì•ˆ: {rejection_reason}

# ì§€ì‹œì‚¬í•­
1. 'ë°˜ë ¤ ì‚¬ìœ  ë° ê°œì„  ì œì•ˆ'ì„ ì™„ë²½í•˜ê²Œ ì´í•´í•˜ê³ , ì§€ì ëœ ëª¨ë“  ë¬¸ì œì ì„ í•´ê²°í•˜ì„¸ìš”.
2. 'ì›ë˜ ì‚¬ìš©ì ìš”ì²­'ì˜ í•µì‹¬ ì˜ë„ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
{dynamic_instruction}

# ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ (ì˜¤ì§ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥):
"""

def recommend_fast_track(state: GraphState):
    print("\n--- 1. ìœ ì‚¬ í…œí”Œë¦¿ ì¶”ì²œ (Fast-Track) ---")
    request = state['original_request']
    similar_docs = retriever_whitelist.invoke(request)
    if not similar_docs:
        print("âœ… ìœ ì‚¬í•œ ê¸°ì¡´ í…œí”Œë¦¿ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë°”ë¡œ ì‹ ê·œ ìƒì„± í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        state['user_choice'] = 'new_template'
        return state
    print("ğŸ’¡ ìš”ì²­í•˜ì‹  ë‚´ìš©ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ê¸°ì¡´ í…œí”Œë¦¿ 3ê°œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    for i, doc in enumerate(similar_docs):
        print("-" * 20 + f"\n  ì¶”ì²œ í…œí”Œë¦¿ {i+1}:\n{doc.page_content}\n" + "-" * 20)
    while True:
        choice = input(f"\nì´ ì¤‘ì—ì„œ ì‚¬ìš©í•˜ì‹¤ í…œí”Œë¦¿ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì‹œê±°ë‚˜, ì‹ ê·œ ìƒì„±ì„ ì›í•˜ì‹œë©´ '4'ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1, 2, 3, 4): ")
        if choice in ['1', '2', '3']:
            state['user_choice'], state['template_draft'] = 'fast_track', similar_docs[int(choice)-1].page_content
            print(f"âœ… {choice}ë²ˆ í…œí”Œë¦¿ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤. ì„ íƒëœ í…œí”Œë¦¿ìœ¼ë¡œ ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            return state
        elif choice == '4':
            state['user_choice'] = 'new_template'
            print("âœ… ì‹ ê·œ í…œí”Œë¦¿ ìƒì„±ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
            return state
        else: print("ğŸš¨ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 1, 2, 3, 4 ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def select_style(state: GraphState):
    print("\n--- 2. ì‹ ê·œ í…œí”Œë¦¿ ìŠ¤íƒ€ì¼ ì„ íƒ ---")
    print("ìƒˆë¡œìš´ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤. ì›í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\n1. ê¸°ë³¸í˜•\n2. ì´ë¯¸ì§€í˜•\n3. ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸í˜•")
    style_map = {'1': 'ê¸°ë³¸í˜•', '2': 'ì´ë¯¸ì§€í˜•', '3': 'ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸í˜•'}
    while True:
        choice = input("\nì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (1, 2, 3): ")
        if choice in style_map:
            state['selected_style'] = style_map[choice]
            print(f"âœ… '{state['selected_style']}' ìŠ¤íƒ€ì¼ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
            return state
        else: print("ğŸš¨ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 1, 2, 3 ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def expand_intent(state: GraphState):
    print("\n--- 3. ì˜ë„ í™•ì¥ ë° ì´ˆì•ˆ ìƒì„± ---")
    original_request, style = state['original_request'], state['selected_style']
    example_docs = retriever_whitelist.invoke(original_request)
    examples = "\n\n".join([f"ì˜ˆì‹œ {i+1}:\n{doc.page_content}" for i, doc in enumerate(example_docs)])
    expansion_chain = expansion_prompt | llm | StrOutputParser()
    expanded_draft = expansion_chain.invoke({"original_request": original_request, "style": style, "examples": examples})
    state['template_draft'] = expanded_draft
    print(f"âœ… ì˜ë„ í™•ì¥ ì™„ë£Œ. ìƒì„±ëœ ì´ˆì•ˆ:\n---\n{expanded_draft}\n---")
    return state

def validate_draft(state: GraphState):
    print(f"\n--- 4. ê·œì • ì¤€ìˆ˜ ê²€ì¦ (AI ì‹œë„: {state.get('correction_attempts', 0) + 1}) ---")
    draft = state['template_draft']
    parser = JsonOutputParser(pydantic_object=TemplateAnalysisResult)
    step_back_chain = ChatPromptTemplate.from_template("ì´ í…œí”Œë¦¿ì˜ í•µì‹¬ ìŸì ì€ ë¬´ì—‡ì¸ê°€?: {draft}") | llm | StrOutputParser()
    step_back_question = step_back_chain.invoke({"draft": draft})
    print(f"   - ìƒì„±ëœ í•µì‹¬ ìŸì : {step_back_question}")
    
    compliance_docs = retriever_compliance.invoke(step_back_question)
    rules_with_metadata = "\n\n".join([f"ë¬¸ì„œ ë©”íƒ€ë°ì´í„°: {doc.metadata}\në¬¸ì„œ ë‚´ìš©: {doc.page_content}" for doc in compliance_docs])
    
    rejected_docs = retriever_rejected.invoke(draft)
    rejections = "\n\n".join([doc.page_content for doc in rejected_docs])
    
    validation_chain = validation_prompt_structured | llm | parser
    result = validation_chain.invoke({"draft": draft, "rules": rules_with_metadata, "rejections": rejections, "format_instructions": parser.get_format_instructions()})
    
    state['validation_result'] = TemplateAnalysisResult.model_validate(result)
    if state['validation_result'].status == 'accepted':
        print("âœ… ê²€ì¦ ê²°ê³¼: í†µê³¼")
    else:
        print(f"ğŸš¨ ê²€ì¦ ê²°ê³¼: ìœ„ë°˜ ë°œê²¬")
        print(f"   - ìƒì„¸ ì´ìœ :\n{state['validation_result'].reason}")
        print(f"   - ê°œì„  ì œì•ˆ: {state['validation_result'].suggestion}")
    return state

def self_correct_draft(state: GraphState):
    print("\n--- 5. AI ìê°€ ìˆ˜ì • ì‹œì‘ ---")
    
    attempts = state.get('correction_attempts', 0)
    
    if attempts == 0:
        instruction = "3. ê´‘ê³ ì„± ë¬¸êµ¬ë¥¼ ì œê±°í•˜ê±°ë‚˜, ì •ë³´ì„± ë‚´ìš©ìœ¼ë¡œ ìˆœí™”í•˜ëŠ” ë“±, ì œì•ˆëœ ë°©í–¥ì— ë§ê²Œ í…œí”Œë¦¿ì„ ìˆ˜ì •í•˜ì„¸ìš”."
    elif attempts == 1:
        instruction = "3. **(2ì°¨ ìˆ˜ì •)** ì•„ì§ë„ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” 'ì¿ í°', 'í• ì¸', 'ì´ë²¤íŠ¸', 'íŠ¹ê°€'ì™€ ê°™ì€ ëª…ë°±í•œ ê´‘ê³ ì„± ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. ëŒ€ì‹  'ê³ ê°ë‹˜ê»˜ ì ìš© ê°€ëŠ¥í•œ í˜œíƒ', 'ìƒˆë¡œìš´ ì†Œì‹'ê³¼ ê°™ì€ ì •ë³´ì„± í‘œí˜„ìœ¼ë¡œ ìˆœí™”í•˜ì—¬ ë‹¤ì‹œ ì‘ì„±í•´ë³´ì„¸ìš”."
    else:
        instruction = """3. **(ìµœì¢… ìˆ˜ì •: ê´€ì  ì „í™˜)** ì—¬ì „íˆ ê´‘ê³ ì„±ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ê²ƒì´ ë§ˆì§€ë§‰ ì‹œë„ì…ë‹ˆë‹¤.
        - **ê´€ì  ì „í™˜:** ë©”ì‹œì§€ì˜ ì£¼ì²´ë¥¼ 'ìš°ë¦¬(ì‚¬ì—…ì)'ì—ì„œ 'ê³ ê°ë‹˜'ìœ¼ë¡œ ì™„ì „íˆ ë°”ê¾¸ì„¸ìš”.
        - **ëª©ì  ë³€ê²½:** 'íŒë§¤'ë‚˜ 'ë°©ë¬¸ ìœ ë„'ê°€ ì•„ë‹ˆë¼, 'ê³ ê°ë‹˜ì´ ê³¼ê±°ì— ë™ì˜í•œ ë‚´ìš©ì— ë”°ë¼ ê³ ê°ë‹˜ì˜ ê¶Œë¦¬(í˜œíƒ) ì •ë³´ë¥¼ ì•ˆë‚´'í•˜ëŠ” ê²ƒìœ¼ë¡œ ëª©ì ì„ ì¬ì •ì˜í•˜ì„¸ìš”.
        - **ê·¼ê±° ì œì‹œ:** ë©”ì‹œì§€ í•˜ë‹¨ì— 'â€» ë³¸ ë©”ì‹œì§€ëŠ” OOO ì •ë³´ ìˆ˜ì‹ ì— ë™ì˜í•˜ì‹  ê³ ê°ë‹˜ê»˜ë§Œ ë°œì†¡ë©ë‹ˆë‹¤.'ì™€ ê°™ì´, ì´ ë©”ì‹œì§€ê°€ ìŠ¤íŒ¸ì´ ì•„ë‹Œ ê·¼ê±°ë¥¼ ëª…í™•íˆ í¬í•¨ì‹œí‚¤ì„¸ìš”.
        - **í‘œí˜„ ìˆœí™”:** 'í• ì¸ìœ¨', 'í–‰ì‚¬' ê°™ì€ ì§ì ‘ì ì¸ ë‹¨ì–´ë¥¼ 'ìš°ëŒ€ í˜œíƒ', 'ì ìš© ê°€ëŠ¥' ë“±ìœ¼ë¡œ ìµœëŒ€í•œ ìˆœí™”í•˜ì„¸ìš”."""

    base_prompt = ChatPromptTemplate.from_template(correction_prompt_template)
    correction_prompt = base_prompt.partial(dynamic_instruction=instruction)
    
    correction_chain = correction_prompt | llm | StrOutputParser()
    
    new_draft = correction_chain.invoke({
        "original_request": state['original_request'],
        "rejected_draft": state['template_draft'],
        "rejection_reason": state['validation_result'].reason + "\nê°œì„  ì œì•ˆ: " + state['validation_result'].suggestion
    })
    
    state['template_draft'] = new_draft
    state['correction_attempts'] = attempts + 1
    
    print(f"âœ… AI ìê°€ ìˆ˜ì • ì™„ë£Œ. ìˆ˜ì •ëœ ì´ˆì•ˆ:\n---\n{new_draft}\n---")
    return state

# --- [ì‹ ê·œ ì¶”ê°€] ì¸ê°„-AI í˜‘ì—… ë…¸ë“œ ---
def human_in_the_loop(state: GraphState):
    print("\n--- 6. AI ìµœì¢… ì‹¤íŒ¨: ì‚¬ìš©ì ìˆ˜ì • ë‹¨ê³„ ---")
    print("ğŸ”¥ AIê°€ ëª¨ë“  ìˆ˜ì •ì„ ì‹œë„í–ˆì§€ë§Œ, ìµœì¢…ì ìœ¼ë¡œ ê·œì • ì¤€ìˆ˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    print("\në§ˆì§€ë§‰ìœ¼ë¡œ ë°˜ë ¤ëœ ì´ˆì•ˆì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:")
    print("-" * 20)
    print(state['template_draft'])
    print("-" * 20)
    print("\në°˜ë ¤ ì‚¬ìœ :")
    print(state['validation_result'].reason)
    print("\nê°œì„  ì œì•ˆ:")
    print(state['validation_result'].suggestion)
    
    while True:
        choice = input("\nì§ì ‘ ìˆ˜ì •í•˜ì—¬ ë§ˆì§€ë§‰ ê²€ì¦ì„ ì‹œë„í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
        if choice == 'y':
            print("\ní…œí”Œë¦¿ì„ ì§ì ‘ ìˆ˜ì •í•´ì£¼ì„¸ìš”. (ìˆ˜ì •ì„ ë§ˆì¹˜ë ¤ë©´ Enter í‚¤ë¥¼ ë‘ ë²ˆ ëˆ„ë¥´ì„¸ìš”)")
            user_input_lines = []
            while True:
                line = input()
                if not line:
                    break
                user_input_lines.append(line)
            
            user_edited_draft = "\n".join(user_input_lines)
            if not user_edited_draft.strip():
                print("ğŸš¨ ì…ë ¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ì •ì„ ì·¨ì†Œí•©ë‹ˆë‹¤.")
                state['user_choice'] = 'exit'
                return state

            state['template_draft'] = user_edited_draft
            state['correction_attempts'] = 99 # ì‚¬ìš©ìê°€ ìˆ˜ì •í–ˆìŒì„ ë‚˜íƒ€ë‚´ëŠ” í”Œë˜ê·¸
            print("\nâœ… ì‚¬ìš©ì ìˆ˜ì •ì•ˆì´ ì ‘ìˆ˜ë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ìµœì¢… ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            return state
        elif choice == 'n':
            print("âœ… ìˆ˜ì •ì„ í¬ê¸°í•˜ì…¨ìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            state['user_choice'] = 'exit'
            return state
        else:
            print("ğŸš¨ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤. 'y' ë˜ëŠ” 'n'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def decide_fast_track_path(state: GraphState):
    return "validate_draft" if state['user_choice'] == 'fast_track' else "select_style"

def decide_next_step(state: GraphState):
    if state['validation_result'].status == 'accepted':
        return "end"
    elif state.get('correction_attempts', 0) < MAX_CORRECTION_ATTEMPTS:
        return "self_correct"
    else:
        # AIì˜ ëª¨ë“  ì‹œë„ê°€ ì‹¤íŒ¨í•˜ë©´, human_in_the_loopë¡œ ì´ë™
        return "human_in_the_loop"

# --- [ì‹ ê·œ ì¶”ê°€] ì‚¬ìš©ì ìˆ˜ì • í›„ì˜ ë¼ìš°í„° ---
def decide_after_human_edit(state: GraphState):
    if state.get('user_choice') == 'exit':
        return "end_with_failure"
    else:
        # ì‚¬ìš©ìê°€ ìˆ˜ì •í•œ í…œí”Œë¦¿ì„ ê²€ì¦í•˜ëŸ¬ ê°
        return "validate_draft"

def build_graph():
    workflow = StateGraph(GraphState)
    workflow.add_node("recommend_fast_track", recommend_fast_track)
    workflow.add_node("select_style", select_style)
    workflow.add_node("expand_intent", expand_intent)
    workflow.add_node("validate_draft", validate_draft)
    workflow.add_node("self_correct_draft", self_correct_draft)
    workflow.add_node("human_in_the_loop", human_in_the_loop) # ì‹ ê·œ ë…¸ë“œ ì¶”ê°€
    
    workflow.set_entry_point("recommend_fast_track")
    workflow.add_conditional_edges("recommend_fast_track", decide_fast_track_path, {"select_style": "select_style", "validate_draft": "validate_draft"})
    workflow.add_edge("select_style", "expand_intent")
    workflow.add_edge("expand_intent", "validate_draft")
    
    workflow.add_conditional_edges(
        "validate_draft",
        decide_next_step,
        {
            "self_correct": "self_correct_draft",
            "end": END,
            "human_in_the_loop": "human_in_the_loop" # ì‹¤íŒ¨ ì‹œ human_in_the_loopë¡œ
        }
    )
    workflow.add_edge("self_correct_draft", "validate_draft")
    
    # --- [ì‹ ê·œ ì¶”ê°€] Human-in-the-loop ê²½ë¡œ ---
    workflow.add_conditional_edges(
        "human_in_the_loop",
        decide_after_human_edit,
        {
            "validate_draft": "validate_draft",
            "end_with_failure": END
        }
    )
    
    return workflow.compile()

if __name__ == "__main__":
    setup_retrievers()
    app = build_graph()
    user_request = input("\nì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ì•Œë¦¼í†¡ í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ ë“œë¦´ê¹Œìš”?\n>> ")
    
    initial_state = {"original_request": user_request, "correction_attempts": 0}
    
    final_state = app.invoke(initial_state)
    print(f"\n================ ìµœì¢… ê²°ê³¼ ================")
    
    final_result = final_state.get('validation_result')
    if final_result:
        # ì‚¬ìš©ìê°€ ìˆ˜ì •ì„ í¬ê¸°í•œ ê²½ìš°, ìµœì¢… ê²°ê³¼ëŠ” ë°˜ë ¤ëœ ìƒíƒœë¡œ ìœ ì§€
        if final_state.get('user_choice') == 'exit':
             final_result.status = 'rejected'
             final_result.revised_template = None

        # ìµœì¢…ì ìœ¼ë¡œ ë°˜ë ¤ëœ ê²½ìš°, ìˆ˜ì •ëœ í…œí”Œë¦¿ì€ null ì²˜ë¦¬
        if final_result.status == 'rejected':
            final_result.revised_template = None
        
        print(json.dumps(final_result.model_dump(), indent=2, ensure_ascii=False))
    else:
        print("ì˜¤ë¥˜: íŒŒì´í”„ë¼ì¸ì´ ìµœì¢… ìƒíƒœë¥¼ ë°˜í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    print("============================================")
